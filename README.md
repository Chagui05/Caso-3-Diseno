# Caso-3-Diseno

## 1. Planeamiento

En esta secci√≥n se detallan los aspectos relacionados con la comprensi√≥n del problema, la forma en que se dividir√° el trabajo dentro del equipo, los hitos en los que se estructura el desarrollo del proyecto y los mecanismos que permitir√°n evaluar si se est√° avanzando conforme a lo planificado.

### 1.1 Estructura del Equipo, Stakeholders, Key Players

#### Estructura Interna

El equipo de trabajo consiste de 5 integrantes:

- Santiago Chaves Garbanzo
- Anthony Fuentes
- Luis David Blanco
- Gabriel Guti√©rrez
- Jefferson Salas Cordero

Todos tenemos asignaciones distintas dentro del proyecto, pero como vamos a trabajar con metodolog√≠a Kanban, cualquiera puede hacerse cargo de cualquier tarea. Basta con elegirla en ClickUp y ponerse a trabjar.

Adem√°s, una pieza muy importante en el proyecto ser√° Rodrigo N√∫√±ez, el cu√°l actuar√° como Product Owner de Data Pura Vida, y consultor de dise√±o de software en caso de que tengamos alg√∫n tipo de duda.

#### Stakeholders y Key Players:

Se identificaron los principales actores que influyen o se ven afectados por el desarrollo de la plataforma. A continuaci√≥n, se presenta una matriz que los muestra:

![matrizstakeholders](img/matriz-stakeholders.png)

Como se puede observar, los principales interesados en que el proyecto avance son el Product Owner y el equipo de trabajo, ya que est√°n comprometidos con lograr que el producto final cumpla con los objetivos planteados desde el inicio.

La poblaci√≥n general, aunque no tiene un alto nivel de poder dentro del proyecto, demuestra un gran inter√©s. Una plataforma de este tipo promover√≠a la transparencia en el acceso a datos y aportar√≠a a un Costa Rica con mayor disponibilidad de informaci√≥n para todos (incluso aunque parte del contenido sea privado).

Por otro lado, el actor con mayor poder es el gobierno, al ser quien financia el proyecto. Su inter√©s se considera moderado, posiblemente por cierto escepticismo respecto al impacto que la plataforma podr√≠a tener sobre su reputaci√≥n.

Finalmente, aquellos actores que incurren en pr√°cticas como el lavado de dinero o evasi√≥n fiscal son los menos interesados, ya que el sistema ofrecer√≠a mayor visibilidad sobre los datos, lo cual podr√≠a exponer dichas irregularidades.

Ahora bien, ya que se conocen los stakeholders principales se puede evidenciar que los key players son tanto el Product Owner, como el Equipo de trabajo, ya que ser√°n los encargados de que el proyecto tenga exito.

#### Sistemas y Ecosistemas de Software Existentes:

En Costa Rica no existe ning√∫n sistema ni ecosistema previo que funcione como antecedente directo de Data Pura Vida, por lo que no se anticipan problemas de integraci√≥n con plataformas existentes. Si bien existen herramientas puntuales, como el API del TSE para consultas por c√©dula, estas no representan un obst√°culo, ya que los requerimientos del proyecto contemplan la capacidad del sistema para aceptar datos provenientes de APIs externas.

### 1.2 Gesti√≥n de la Comunicaci√≥n y Documentaci√≥n del proyecto

Para la comunicaci√≥n interna del equipo se utilizar√° Slack. A trav√©s de esta herramienta se coordinar√° la asignaci√≥n de tareas en ClickUp, y tambi√©n se notificar√° cuando una tarea haya sido finalizada. Antes de marcarla como completada, la tarea deber√° pasar al estado de "Esperando Aprobaci√≥n" en ClickUp, para que Rodrigo pueda revisarla y aprobarla.

Adem√°s, se utilizar√° Discord para realizar al menos una reuni√≥n semanal, en la cual se discutir√°n avances generales del proyecto. En caso de surgir dudas m√°s complejas, se invitar√° al profesor para que pueda brindar orientaci√≥n.

La documentaci√≥n principal del proyecto se mantendr√° en el README del repositorio de GitHub Chagui05/Caso-3-Diseno. En ese archivo se incluir√°n todos los detalles relevantes. Si existieran anexos, como la hoja de requerimientos o la entrevista con el profesor, se agregar√°n al mismo repositorio en archivos separados con nombres descriptivos, y se har√° referencia a ellos desde el README. Toda la documentaci√≥n ser√° escrita en formato Markdown.

### 1.3 Entendimiento del problema

Para entender adecuadamente el problema, el equipo realiz√≥ una entrevista al Product Owner, basada en una serie de preguntas que surgieron tras revisar la especificaci√≥n del proyecto. Las respuestas obtenidas fueron registradas en el archivo RespuestaEntrevista, y permitieron extraer informaci√≥n clave, como por ejemplo:

- La plataforma debe permitir el registro de personas f√≠sicas primero, y luego dar la posibilidad de vincularlas como administradoras de organizaciones.
- La validaci√≥n de cuentas puede involucrar m√∫ltiples m√©todos: revisi√≥n manual, validaciones automatizadas y uso de servicios externos como SumSub.
- La inclusi√≥n de IBAN y datos de tarjetas en el registro busca filtrar usuarios no comprometidos y evitar registros superficiales.
- Se recomienda restringir el acceso por IP solo a la secci√≥n de registro, o permitir el registro de IPs confiables para quienes est√©n en el extranjero.
- Los datos cargados (sin importar el origen) deben convertirse a un formato unificado tras aplicar el proceso ETDL (relacional, documental, etc.).
- El sistema debe validar estructura, formato y contenido de los datasets, considerando reglas como formatos de fechas, booleanos y tipos de datos.
- El motor de visualizaci√≥n de dashboards debe permitir a los usuarios crear sus propios paneles, compartirlos y gestionarlos.
- La arquitectura de backend puede ser definida libremente por el equipo (monol√≠tica o microservicios), seg√∫n convenga al dise√±o general.
- Se permite la integraci√≥n con herramientas de IA, siempre que se respeten los criterios de autorizaci√≥n definidos por la administraci√≥n de la plataforma.
- El portal web de backoffice ser√° administrado por una organizaci√≥n gubernamental registrada dentro del sistema, actuando como custodio de la informaci√≥n.

A partir de esta informaci√≥n, se desarrollaron los siguientes diagramas de flujo que ilustran las tareas clave identificadas dentro del sistema:

- Diagrama de registro:

El siguiente diagrama presenta una visi√≥n general del proceso de registro en nuestra plataforma. No incluye detalles t√©cnicos ni especificaciones sobre los campos din√°micos que var√≠an seg√∫n el tipo de entidad registrada; su objetivo es ilustrar de forma abstracta y comprensible c√≥mo se estructura el flujo de registro dentro del sistema.

![matrizstakeholders](img/entendimientoRegistro.png)

- Diagrama de Ingesta y configuraci√≥n de un dataset

Subir y configurar un dataset en la plataforma no es nada trivial, por eso se armaron estos dos diagramas que separan el proceso en dos partes.

El primer diagrama muestra c√≥mo se le pide al usuario que suba el dataset: qu√© datos tiene que dar, qu√© informaci√≥n se necesita para la IA, y c√≥mo se valida el archivo que subi√≥ (formato, estructura, nombres de columnas, etc.).

![matrizstakeholders](img/subidaDataset1.png)

El segundo diagrama arranca una vez que el dataset ya fue validado. Ah√≠ se definen cosas como si el conjunto de datos va a ser p√∫blico, privado o de pago, y qu√© m√©todos de acceso y cobro se van a aplicar.

![matrizstakeholders](img/subidaDataset2.png)

Es importante aclarar que en el diagrama II no se detalla paso a paso lo que hace el motor ETDL, pero s√≠ se deja claro que va a encargarse de tareas como: detectar duplicados, relacionar datos con otros ya cargados, ajustar el modelo seg√∫n las conexiones que encuentre, y aplicar autom√°ticamente un flujo con extracci√≥n, transformaci√≥n, limpieza, detecci√≥n de contexto, modelado y carga con ayuda de AI.

#### Componentes del Sistema

Con el fin de lograr una arquitectura modular, segura y mantenible, el sistema se divide en macrocomponentes. Cada uno aborda un conjunto espec√≠fico de requerimientos funcionales y no funcionales. En esta secci√≥n se listan los componentes y sus principales responsabilidades. La implementaci√≥n t√©cnica y subdivisi√≥n de estos se detalla m√°s adelante en el documento.

##### bioregistro verde

Este m√≥dulo gestiona el proceso de incorporaci√≥n de personas f√≠sicas y jur√≠dicas a la plataforma. Abarca desde el llenado de formularios hasta la validaci√≥n de identidad y la emisi√≥n de credenciales digitales. Debe cumplir con regulaciones AML y est√°ndares avanzados de identidad digital.

Requerimientos:

- El componente debe permitir el registro de personas f√≠sicas, jur√≠dicas, instituciones, c√°maras, grupos y empresas.
- El formulario de registro debe adaptarse din√°micamente seg√∫n el tipo de entidad seleccionada.
- El registro de usuarios debe estar asegurado con MFA y biometr√≠a, cumpliendo est√°ndares de identidad digital avanzada.
- El componente debe solicitar y capturar informaci√≥n personal, societaria, legal y tributaria seg√∫n el tipo de entidad.
- El componente debe revisar que cuando se van a asignar personas f√≠sicas a la organizaci√≥n al crearla, efectivamente formen parte de dicho conjunto.
- El registro debe pasar por una etapa de validaci√≥n interna manual para el registro de empresas
- El componente debe implementar validaci√≥n autom√°tica por inteligencia artificial de los documentos subidos.
- El componente debe exigir a los representantes legales el registro como individuos con: identidad digital, biometr√≠a, prueba de vida y autenticaci√≥n multifactor (MFA).
- Cada organizaci√≥n debe recibir llaves de seguridad que le permitan delegar o revocar accesos a sus usuarios.
- Un usuario debe poder administrar m√∫ltiples organizaciones desde una √∫nica cuenta.
- El componente debe capturar datos preliminares de cuentas IBAN y/o tarjetas de cr√©dito como parte del registro.
- El componente debe enviar una notificaci√≥n por correo electr√≥nico cuando un registro sea aprobado.
- El componente debe exigir documentos espec√≠ficos seg√∫n el tipo de entidad: c√©dulas f√≠sicas o jur√≠dicas, actas, RTN, direcci√≥n, etc.
- El componente debe permitir registrar direcciones IP institucionales (listas blancas) para permitir acceso autorizado.
- El componente debe permitir √∫nicamente IPs costarricenses en el registro
- El sistema debe proteger las claves generadas mediante un esquema de llave tripartita, distribuidas entre Data Pura Vida y dos custodios.


##### La B√≥veda

La B√≥veda es el almac√©n central de datos del sistema, dise√±ado para ser seguro, escalable y auditable. Unifica todos los datos cargados, sin importar su formato de origen, y permite relaciones entre datasets. Cifra la informaci√≥n en tr√°nsito y reposo, controla el acceso por roles y entidades, y mantiene trazabilidad completa del uso y movimientos de los datos. Est√° pensada para soportar millones de registros con alto rendimiento y cumplir est√°ndares de gobierno de datos.

Requerimientos:

- La B√≥veda tiene que almacenar los datos en un solo formato, por m√°s de que las fuentes externas sean de distintos tipos (relacionales, documentales, csv, excel)
- La B√≥veda debe permitir especificar columnas que relacionan un dataset con otros datasets del ecosistema.
- La B√≥veda debe de estar monitoreada en todo momento para detectar movimientos sospechosos, para dar contenido de uso de un dataset, y para asegurar trazabilidad y diagn√≥stico r√°pido de fallas.
- Debe ser resiliente, auditable y alineado con est√°ndares de gobierno de datos.
- Debe permitir crecimiento din√°mico sin perder eficiencia.
- Debe escalar a millones de registros y miles de usuarios concurrentes.
- Mantener trazabilidad de datos usados, no usados y descartados.
- Todos los datos cargados deben estar protegidos mediante cifrado, incluso frente al personal t√©cnico ("ingenieros de la plataforma").
- Cifrar toda la data en tr√°nsito y en reposo, dejando trazabilidad auditable.
- Permitir almacenamiento masivo de datos estructurados y semiestructurados.
- Controlar accesos l√≥gicos por entidad, usuario o tipo de dato.
- Implementar control de acceso a nivel de rol (RBAC) y a nivel de fila (RLS) o equivalentes.

##### M√≥dulo de Ingesta de dato / posibles nombres: El Ingestor, Centro de Carga, Dock de Datos

Este m√≥dulo permite a los usuarios cargar sus datasets a la plataforma. Desde ac√° pueden definir qu√© datos desean cifrar, especificar el formato de origen y configurar otros par√°metros clave para asegurar que la carga se procese correctamente.

Requerimientos: 

- Permitir a los usuarios decidir qu√© datos compartir dentro del ecosistema.
- Requerir que cada dataset tenga un nombre √∫nico.
- Soportar m√∫ltiples m√©todos de carga de datos: archivos Excel, CSV, JSON, APIs y conexiones directas a bases de datos SQL y NoSQL. 
- Requerir nombre, descripci√≥n y metadata √∫til para IA sobre las columnas del dataset.
- Permitir configurar los par√°metros de conexi√≥n de forma cifrada para cada medio de carga.
- Los par√°metros de conexi√≥n de bases de datos y APIs deben almacenarse de forma cifrada.
- Permitir configurar si el dataset es p√∫blico o privado, gratuito o pagado, permanente o con disponibilidad temporal.
- El sistema de permisos debe prevenir accesos no autorizados a datasets privados o pagos.
- Asignar permisos de acceso a los datasets privados.
- Permitir definir montos de acceso para datasets con modelo de cobro.
- Restringir acceso a datos por tiempo, volumen o frecuencia de consulta.
- Indicar si la carga es √∫nica o recurrente, completa o por deltas.
- Configurar par√°metros para carga por deltas: campos diferenciales, frecuencia (timed pull) o mediante callbacks.
- Habilitar control granular de acceso por instituci√≥n, persona o grupo.


##### M√≥dulo de transformaci√≥n de datos / posibles nombres: Motor de Transformaci√≥n, Procesador ETDL

Este m√≥dulo es clave para garantizar que los datasets se almacenen correctamente en la B√≥veda. Se encarga de recibir datos desde distintas fuentes, validar que el formato coincida con el indicado en el formulario de ingesta y, en caso contrario, rechazar la carga. Una vez superada esta validaci√≥n, aplica todo el proceso de ETDL y mapea los datos al formato interno de la B√≥veda.

Requerimientos: 

- Validar el formato, estructura y contenido de cada dataset cargado sea correcto, o bien adaptarlo al interno de la B√≥veda (formatos de fecha, booleans, etc.).
- Validar el formato, estructura y contenido de cada dataset cargado coincida con lo especificado en el proceso de carga.
- Automatizar el proceso de carga mediante un motor de IA que aplique un flujo ETDL (extracci√≥n, transformaci√≥n, limpieza, detecci√≥n de contexto, modelado y carga).
- Aplicar IA para normalizar, redise√±ar modelos de datos y vincularlos autom√°ticamente.
- Detectar duplicidades, optimizar relaciones y ajustar el modelo de datos autom√°ticamente seg√∫n las interrelaciones detectadas.
- Monitorear el proceso completo con m√©tricas de transferencia, carga, limpieza, eliminaci√≥n, modelado, volumen, datos omitidos, datos consultados y tasa de √©xito.
- El sistema debe ser capaz de procesar cargas recurrentes y automatizadas sin intervenci√≥n manual.
- Soportar cargas delta con identificaci√≥n de cambios.
- Realizar merges eficientes sin p√©rdida de integridad.

##### Centro de Visualizaci√≥n y Consumo

Este m√≥dulo est√° compuesto por 3 subcomponentes clave:


1. **Generador de dashboards**: permite a los usuarios dise√±ar y crear gr√°ficos de forma r√°pida y amigable para visualizar cualquier dataset.

Requerimientos:
- El sistema debe permitir la construcci√≥n de dashboards personalizados de forma manual.
- El sistema debe permitir construir dashboards manualmente o mediante prompts inteligentes que generen visualizaciones autom√°ticas.
- El sistema debe permitir representar visualmente los datos en tablas, gr√°ficos, conteos, tendencias y predicciones.
- El sistema debe permitir a los usuarios guardar sus dashboards personalizados.
- El sistema debe permitir compartir dashboards con otros usuarios o hacerlos p√∫blicos dentro de la plataforma.
- La interfaz de construcci√≥n de dashboards debe ser segura, intuitiva y con capacidad de respuesta en tiempo real.

2. **Visualizaci√≥n y Consumo**: ofrece una interfaz para revisar esas visualizaciones y realizar an√°lisis de datos directamente sobre los dashboards.

Requerimientos:
- El sistema debe permitir visualizar todos los datasets accesibles como una fuente consolidada.
- El sistema debe bloquear toda exportaci√≥n directa de datos y gr√°ficos desde el portal.
- El sistema debe mostrar datos de forma preliminar en modo de construcci√≥n de dashboard y luego con datos reales al ejecutar consultas
- El sistema debe deshabilitar temporalmente el acceso a datasets cuando se superen los l√≠mites de consumo.
- El sistema debe registrar todas las transacciones y consumos de datos en un historial accesible para cada usuario.
- El sistema debe mostrar m√©tricas de uso: volumen de datos consultados, n√∫mero de consultas realizadas, tiempo restante o l√≠mites alcanzados.
- El sistema no debe permitir en ning√∫n momento la descarga directa de datasets o gr√°ficos generados.
- La visualizaci√≥n de datos debe realizarse exclusivamente dentro del portal, sin opciones de exportaci√≥n, captura o embedding externo.
- Los l√≠mites de consumo deben aplicarse en tiempo real, sin permitir bypasses o reintentos abusivos.

3. **Consumo para IA**: Este subcomponente es el regulador de consumo de IA, define l√≠mites y los m√©todos de ingesta disponibles desde el sistema para los usuarios. 

Requerimientos:

- El sistema debe permitir el acceso sistema a sistema √∫nicamente para alimentar modelos de IA aprobados.
- La entrega de datos para modelos de IA debe ser monitoreada, registrada y limitada a contextos aprobados expl√≠citamente por Data Pura Vida.
- El sistema debe ofrecer plataformas limitadas y controladas para esta alimentaci√≥n de IA. Solo permitir√° 2 por usuario. 
- El sistema debe minimizar al m√°ximo el riesgo de descargas indirectas mediante presunci√≥n de uso en IA.
- Los datos deben ser env√≠ados en un formato que no permita poder ser desencriptado para otro uso que no sea alimentar IA (por ejemplo uso de embeddings).

##### Marketplace

Este m√≥dulo est√° enfocado en ofrecer una interfaz amigable que permita a los usuarios encontrar datasets de forma eficiente, con descripciones claras y navegaci√≥n fluida. Adem√°s, incluye una secci√≥n adicional para buscar dashboards creados por otros usuarios, facilitando el descubrimiento y reutilizaci√≥n de visualizaciones dentro de la plataforma.

Requerimientos:

- La experiencia de compra de datasets debe ser fluida, transparente y accesible desde los dashboards personales.
- Incluir un m√≥dulo de compra donde se visualicen datasets disponibles bajo acceso pagado.
- Permitir seleccionar un dataset, visualizar precio, t√©rminos de uso, duraci√≥n del acceso y condiciones de cobro.
- Soportar m√∫ltiples m√©todos de pago: tarjeta de cr√©dito, d√©bito y otros mecanismos nacionales compatibles.
- Mostrar confirmaciones de transacci√≥n y activar el acceso seg√∫n condiciones (tiempo, volumen, frecuencia).
- El sistema debe mostrar opciones para renovar o ampliar los paquetes de acceso en caso de superar el l√≠mite.
 

##### Backoffice Administrativo

Este m√≥dulo concentra las herramientas de backoffice necesarias para la gesti√≥n integral de la plataforma. Su enfoque est√° en el control, la seguridad, la gobernanza de datos y la trazabilidad completa de las operaciones. 

Requerimientos:

- Administrar usuarios: validaci√≥n de identidad, membres√≠a y roles.
- Gestionar reglas de carga de datos (formatos, estructuras, validaciones).
- Configurar conexiones externas (APIs, BDs, callbacks).
- Activar, desactivar y supervisar objetos de datos, pipelines y flujos.
- Revocar o regenerar llaves de seguridad (sim√©tricas, asim√©tricas, tri-partitas).
- Administrar custodios de llaves y flujos de confirmaci√≥n mancomunada.
- Auditar operaciones por usuario, fecha, acci√≥n y resultado.
- Generar reportes de uso, calidad, integraci√≥n y anomal√≠as.
- Monitorear el estado operativo de servicios y tareas.
- Extraer evidencias para procesos legales bajo autorizaci√≥n.
- Gestionar permisos y accesos mediante RBAC.
- Debe ofrecer una interfaz robusta y segura solo para personal autorizado.
- Debe permitir gesti√≥n flexible pero estricta de accesos y configuraciones.

#### Prototipado 

Se desarroll√≥ un prototipo funcional de la p√°gina del Bioregistro Verde con el objetivo principal de probar el comportamiento de los formularios din√°micos. Este prototipo no incluye procesos de prueba de vida ni captura de datos biom√©tricos, y tampoco recolecta la informaci√≥n final que se almacenar√° en el sistema definitivo. Su prop√≥sito es demostrar, a alto nivel, c√≥mo el formulario se adapta din√°micamente seg√∫n las selecciones del usuario.

A continuaci√≥n las im√°genes del flujo de recolecci√≥n de data de una persona f√≠sica:

![alt text](img/userReg0.png)

![alt text](img/userReg1.png)

![alt text](img/userReg2.png)

![alt text](img/userReg3.png)

Adem√°s, se adjunta el proceso de registar compa√±√≠a p√∫blica:

![alt text](img/orgPub0.png)
![alt text](img/orgPub1.png)
![alt text](img/orgPub2.png)
![alt text](img/orgPub3.png)
![alt text](img/orgPub4.png)
![alt text](img/orgPub5.png)


Si dese√° probar el prototipo visite el siguiente [link](https://gentle-signup-wizard.lovable.app/).

### 1.4 Customer Journeys

Este Service Blueprint representa el recorrido completo de un ciudadano dentro del ecosistema Data Pura Vida, desde el descubrimiento de la plataforma hasta la creaci√≥n, publicaci√≥n y monitoreo de un dashboard personalizado con datos p√∫blicos.

El diagrama detalla no solo las acciones del usuario, sino tambi√©n los touchpoints del sistema, los procesos internos (backstage) y las herramientas de soporte involucradas en cada etapa. Adem√°s, se integran las emociones del usuario para identificar oportunidades de mejora en la experiencia.

Las l√≠neas de interacci√≥n, visibilidad e interacci√≥n interna permiten visualizar claramente los l√≠mites entre lo que el ciudadano ve, lo que ocurre detr√°s del sistema y las herramientas tecnol√≥gicas que lo sustentan.

Este blueprint se organiza en **seis** fases principales:

1. Conciencia: El ciudadano conoce la existencia de la plataforma.

2. Ingreso: Accede y se autentica de forma segura.

3. Exploraci√≥n: Navega los datasets disponibles.

4. Creaci√≥n: Construye un dashboard visual con datos abiertos.

5. Publicaci√≥n: Comparte su dashboard con otros usuarios.

6. Monitoreo: Consulta m√©tricas de visualizaci√≥n y uso.b

![alt text](img/journey1.png)

Este Service Blueprint representa el recorrido completo de una empresa dentro del ecosistema Data Pura Vida, desde el descubrimiento de la plataforma hasta la publicaci√≥n y monitoreo de un dataset privado con fines de monetizaci√≥n.

Este blueprint se organiza en siete fases principales:

1. Conciencia: La empresa conoce la plataforma y sus posibilidades de monetizaci√≥n.

2. Registro: Se registra como entidad jur√≠dica mediante un proceso validado.

3. Carga de datos: Sube su dataset en formatos compatibles como archivos o APIs.

4. Configuraci√≥n: Define permisos, privacidad, cifrado y condiciones de acceso.

5. Validaci√≥n de valor: Eval√∫a la calidad y el potencial del dataset con ayuda de IA.

6. Publicaci√≥n: Hace p√∫blico el dataset con opciones de pago o acceso controlado.

7. Monitoreo: Supervisa ingresos, visualizaciones y transacciones en tiempo real.

![alt text](img/journeyIP.png)

**Fases principales:**

1. Registro: Un representante oficial crea una cuenta institucional y sube los documentos requeridos.
2. Validaci√≥n: La plataforma aplica validaciones autom√°ticas y manuales con ayuda de IA.
3. Configuraci√≥n: La instituci√≥n decide qu√© datos compartir y con qu√© restricciones.
4. Carga: Se conecta una base de datos externa para carga automatizada.
5. Publicaci√≥n: El dataset queda disponible para actores autorizados mediante pago.
6. Seguimiento: La instituci√≥n consulta m√©tricas de acceso y consumo.

![alt text](img/journey2.png)

### 1.5 Plan de ejecuci√≥n del proyecto

El proyecto se estructura en cinco hitos principales que marcar√°n su progreso:

- Planeamiento del Proyecto
- Supuestos del Proyecto
- Stack Tecnol√≥gico
- Dise√±o de los Componentes
- Validaci√≥n de los requerimientos

Cada uno de estos hitos cuenta con un plazo definido para su ejecuci√≥n, lo cual se puede observar en el siguiente diagrama de Gantt:

![gantt](img/gantt.png)

Dentro de cada hito se contemplan varias tareas. Cada integrante del equipo debe seleccionar una tarea seg√∫n su disponibilidad. Un hito se considera finalizado √∫nicamente cuando todas sus tareas han sido completadas y se encuentran en el tablero de completado en ClickUp.

Adem√°s, como se indic√≥ anteriormente, se realizar√°n reuniones semanales para verificar que el proyecto avance conforme al plan establecido.

Adem√°s, como se dijo previamente, se har√°n reuniones semanales para verificar que el proyecto se est√© realizando seg√∫n lo dice el plan.

### 1.6 WBS del sistema

Como parte del an√°lisis inicial del sistema **Data Pura Vida**, se realiz√≥ una descomposici√≥n de alto nivel para identificar los l√≠mites del sistema y los actores involucrados. A continuaci√≥n, se presenta el diagrama de contexto basado en las t√©cnicas descritas para la identificaci√≥n del sistema y sus l√≠mites:

![Work Breakdown Structure](img/WorkBreakdownStructure.jpg)

Esta representaci√≥n facilita el entendimiento general del sistema y servir√° como base para la posterior descomposici√≥n en subsistemas, componentes funcionales y dise√±o arquitect√≥nico detallado.

#### Prop√≥sito del diagrama
- **Identificaci√≥n de l√≠mites del sistema:** El diagrama establece una frontera clara entre lo que est√° dentro y fuera del alcance del desarrollo, lo cual es crucial para evitar ambig√ºedades durante el dise√±o detallado.

- **Visualizaci√≥n de los actores externos:** Permite entender qui√©nes interact√∫an con el sistema y con qu√© prop√≥sito.

- **Detecci√≥n de puntos de integraci√≥n:** Ayuda a anticipar necesidades de interoperabilidad, seguridad, formatos de intercambio de datos y protocolos de comunicaci√≥n.

#### Consideraciones adicionales
Este diagrama ser√° utilizado como punto de partida para:

- La descomposici√≥n en subsistemas o m√≥dulos funcionales, agrupando responsabilidades afines.

- La definici√≥n de casos de uso y escenarios de interacci√≥n.

- La elaboraci√≥n de la arquitectura t√©cnica, donde se identificar√°n servicios, componentes y flujos de datos internos.

En resumen, este modelo de contexto es una herramienta clave para asegurar un entendimiento compartido del dominio del problema y sentar las bases de una soluci√≥n t√©cnica coherente, escalable y alineada con los objetivos del proyecto.

# 1.7 Evaluaci√≥n de Riesgos

## Metodolog√≠a ISO 31000

La evaluaci√≥n de riesgos sigue los principios de **ISO 31000** para la gesti√≥n de riesgos del proyecto Data Pura Vida.

## Marco de Evaluaci√≥n:

La evaluaci√≥n de riesgos utiliza una matriz de probabilidad versus impacto basada en criterios espec√≠ficos del proyecto Data Pura Vida y su contexto de dise√±o de sistemas complejos.

### Escala de probabilidad:

- Muy Alta (100%) : Es pr√°cticamente seguro que el riesgo ocurrir√° durante el proyecto (9 de cada 10 proyectos similares)
- Alta (80%) : Es muy probable que el riesgo se materialice (7-8 de cada 10 casos)
- Medios (60%) : Hay una posibilidad moderada de que ocurra (5-6 de cada 10 casos)
- Baja (40%) : Es poco probable pero posible que suceda (3-4 de cada 10 casos)
- Muy Baja (20%) : Es muy poco probable que se materialice (1-2 de cada 10 casos)

### Escala de Impacto:

- Muy Alto (100%) : Falla completa del proyecto, redise√±o total necesario, o retraso superior a 4 semanas
- Alto (80%) : Compromete objetivos principales del proyecto, retraso de 2-4 semanas, o afecta m√∫ltiples componentes cr√≠ticos
- Medio (60%) : Afecta la calidad del dise√±o o genera retraso de 1-2 semanas, requiere trabajo adicional significativo
- Bajo (40%) : Impacto menor en cronograma (3-7 d√≠as) o calidad, se puede resolver con ajustes menores
- Muy Bajo (20%) : Impacto m√≠nimo (menos de 3 d√≠as), no afecta objetivos principales del proyecto

## Riesgos para el Dise√±o de Data Pura Vida

| ID      | Categor√≠a         | Riesgo                                               | Descripci√≥n Detallada                                                                                                                                                                           | Probabilidad        | Impacto             | Clasificaci√≥n   | Estrategia     | Plan de Respuesta                                                                                                                                                                 |
| ------- | ----------------- | ---------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------- | ------------------- | --------------- | -------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **R01** | **Dise√±o**        | **Complejidad arquitect√≥nica del ecosistema**        | Dise√±ar una arquitectura que integre efectivamente portal web, API backend, datalake, backoffice y m√∫ltiples sistemas de seguridad requiere experiencia en arquitecturas distribuidas complejas | **Muy Alta (100%)** | **Muy Alto (100%)** | **üî¥ EXTREMO**  | **MITIGAR**    | **Prevenci√≥n:** Definir patrones arquitect√≥nicos est√°ndar, revisiones semanales, divisi√≥n en capas<br>**Contingencia:** Consultor√≠a externa, arquitectura monol√≠tica simplificada |
| **R02** | **Alcance**       | **Subestimaci√≥n del alcance t√©cnico**                | El sistema requiere dise√±ar m√°s de 50 componentes t√©cnicos diferentes incluyendo motor ETDL con IA, cifrado tripartito, validaci√≥n biom√©trica y procesamiento de millones de registros          | **Alta (80%)**      | **Alto (80%)**      | **üü† ALTO**     | **MITIGAR**    | **Prevenci√≥n:** Descomponer en historias simples, Planning Poker, estimaci√≥n por horas<br>**Contingencia:** Re-priorizaci√≥n MoSCoW, reducci√≥n a MVP                               |
| **R03** | **Documentaci√≥n** | **Inconsistencias en la documentaci√≥n t√©cnica**      | Generar documentaci√≥n t√©cnica coherente entre arquitectura de alto nivel, especificaciones de APIs, modelos de datos, diagramas de seguridad y patrones de integraci√≥n                          | **Alta (80%)**      | **Alto (80%)**      | **üü† ALTO**     | **MITIGAR**    | **Prevenci√≥n:** Templates est√°ndar, peer review, checklist calidad<br>**Contingencia:** Auditor√≠a semanal, refactoring documental                                                 |
| **R04** | **Tiempo**        | **Cronograma optimista para la complejidad**         | El tiempo asignado puede ser insuficiente para dise√±ar completamente todos los componentes t√©cnicos con el nivel de detalle requerido para un sistema de esta magnitud                          | **Muy Alta (100%)** | **Medio (60%)**     | **üü† ALTO**     | **MITIGAR**    | **Prevenci√≥n:** Re-estimaci√≥n semanal, burndown charts, escalaci√≥n autom√°tica<br>**Contingencia:** Priorizaci√≥n din√°mica, redistribuci√≥n de tareas                                |
| **R05** | **T√©cnico**       | **Complejidad del motor ETDL con IA**                | Especificar t√©cnicamente un motor que procese autom√°ticamente m√∫ltiples formatos, detecte duplicados, relacione datos y aplique transformaciones inteligentes es altamente complejo             | **Media (60%)**     | **Muy Alto (100%)** | **üü† ALTO**     | **MITIGAR**    | **Prevenci√≥n:** Spike 16 horas, prototipo con 3 casos, arquitectura modular<br>**Contingencia:** Motor simplificado sin IA, integraci√≥n Talend/NiFi                               |
| **R06** | **Seguridad**     | **Dise√±o de sistema de cifrado tripartito**          | Especificar correctamente un sistema de llaves criptogr√°ficas divididas entre tres custodios, incluyendo protocolos de recuperaci√≥n y validaci√≥n mancomunada                                    | **Baja (40%)**      | **Muy Alto (100%)** | **üü† ALTO**     | **TRANSFERIR** | **Prevenci√≥n:** Consulta expertos, est√°ndares FIPS 140-2, validaci√≥n externa<br>**Contingencia:** Cifrado HSM tradicional, esquema dual                                           |
| **R07** | **Integraci√≥n**   | **Interfaces entre componentes mal definidas**       | Riesgo de que las especificaciones de APIs, contratos de datos y protocolos de comunicaci√≥n entre portal, backend y datalake no sean completamente compatibles                                  | **Media (60%)**     | **Alto (80%)**      | **üü† ALTO**     | **MITIGAR**    | **Prevenci√≥n:** Contratos OpenAPI 3.0, reuniones bi-semanales, diagramas secuencia<br>**Contingencia:** Workshop alineaci√≥n 4 horas, redise√±o contratos                           |
| **R08** | **Escalabilidad** | **Arquitectura no preparada para la carga esperada** | El dise√±o puede no contemplar adecuadamente el manejo de millones de registros, miles de usuarios concurrentes y procesamiento de grandes vol√∫menes de datos                                    | **Baja (40%)**      | **Medio (60%)**     | **üü° MODERADO** | **ACEPTAR**    | **Prevenci√≥n:** An√°lisis capacidad inicial, documentar recomendaciones<br>**Contingencia:** Roadmap escalabilidad futura, patrones horizontales                                   |
| **R09** | **Recursos**      | **Disponibilidad limitada del Product Owner**        | El Product Owner puede no estar disponible para validar decisiones arquitect√≥nicas cr√≠ticas o para resolver ambig√ºedades en los requerimientos t√©cnicos                                         | **Media (60%)**     | **Bajo (40%)**      | **üü° MODERADO** | **ACEPTAR**    | **Prevenci√≥n:** Agenda fija martes/viernes, decisiones escritas, timeboxing 24h<br>**Contingencia:** Escalaci√≥n stakeholders, decisiones equipo con validaci√≥n posterior          |
| **R10** | **Coordinaci√≥n**  | **Dise√±os de componentes desconectados**             | Los diferentes integrantes del equipo pueden dise√±ar sus componentes sin suficiente coordinaci√≥n, resultando en interfaces incompatibles o duplicaci√≥n de funcionalidades                       | **Media (60%)**     | **Medio (60%)**     | **üü° MODERADO** | **MITIGAR**    | **Prevenci√≥n:** Sincronizaci√≥n semanal viernes, documentaci√≥n GitHub, daily stand-ups<br>**Contingencia:** Workshop alineaci√≥n medio d√≠a, redise√±o interfaces                     |

# 1.8 Definici√≥n de KPIs

## KPIs por Hito del Proyecto

### Hito 1: Planeamiento del Proyecto

**Per√≠odo**: 18-22 Mayo 2025 (Semana W20)

| KPI                              | M√©trica                            | Objetivo | M√©todo de Recolecci√≥n                              |
| -------------------------------- | ---------------------------------- | -------- | -------------------------------------------------- |
| **Cumplimiento de cronograma**   | % de tareas completadas a tiempo   | 100%     | ClickUp - estado de tareas vs. fechas planificadas |
| **Completitud de documentaci√≥n** | % de entregables documentados      | 100%     | Revisi√≥n de README y archivos en GitHub            |
| **Participaci√≥n del equipo**     | % de integrantes activos en tareas | 100%     | ClickUp - asignaci√≥n y progreso de tareas          |
| **Validaci√≥n del Product Owner** | % de entregables aprobados         | 100%     | Estado "Aprobado" en ClickUp                       |

### Hito 2: Supuestos del Proyecto

**Per√≠odo**: 25-31 Mayo 2025 (Semana W21)

| KPI                            | M√©trica                              | Objetivo | M√©todo de Recolecci√≥n                            |
| ------------------------------ | ------------------------------------ | -------- | ------------------------------------------------ |
| **Cumplimiento de cronograma** | % de tareas completadas a tiempo     | 100%     | ClickUp - comparaci√≥n fecha planificada vs. real |
| **Calidad de supuestos**       | N√∫mero de supuestos validados con PO | 100%     | Documentaci√≥n de validaciones en Slack/GitHub    |
| **Identificaci√≥n de riesgos**  | N√∫mero de riesgos documentados       | ‚â•10      | Matriz de riesgos actualizada                    |

### Hito 3: Stack Tecnol√≥gico

**Per√≠odo**: 1-7 Junio 2025 (Semana W22)

| KPI                               | M√©trica                                       | Objetivo | M√©todo de Recolecci√≥n                        |
| --------------------------------- | --------------------------------------------- | -------- | -------------------------------------------- |
| **Cumplimiento de cronograma**    | % de tareas completadas a tiempo              | 100%     | ClickUp - estado vs. cronograma              |
| **Decisiones tecnol√≥gicas**       | % de tecnolog√≠as seleccionadas y justificadas | 100%     | Documentaci√≥n t√©cnica en GitHub              |
| **Factibilidad t√©cnica**          | Prototipos de concepto funcionando            | ‚â•2       | Repositorio con ejemplos funcionales         |
| **Compatibilidad con requisitos** | % de requisitos cubiertos por stack           | 100%     | Matriz de trazabilidad requisitos-tecnolog√≠a |

### Hito 4: Dise√±o de los Componentes

**Per√≠odo**: 8-14 Junio 2025 (Semana W23)

| KPI                               | M√©trica                                   | Objetivo | M√©todo de Recolecci√≥n                 |
| --------------------------------- | ----------------------------------------- | -------- | ------------------------------------- |
| **Cumplimiento de cronograma**    | % de tareas completadas a tiempo          | 100%     | ClickUp - seguimiento diario          |
| **Cobertura de componentes**      | % de componentes dise√±ados vs. requeridos | 100%     | Documentaci√≥n de arquitectura         |
| **Calidad del dise√±o**            | Revisiones aprobadas por PO               | 100%     | Estados de aprobaci√≥n en ClickUp      |
| **Integraci√≥n entre componentes** | % de interfaces definidas                 | 100%     | Diagramas de integraci√≥n documentados |

### Hito 5: Validaci√≥n de los Requerimientos

**Per√≠odo**: 15-21 Junio 2025 (Semana W24)

| KPI                            | M√©trica                           | Objetivo | M√©todo de Recolecci√≥n             |
| ------------------------------ | --------------------------------- | -------- | --------------------------------- |
| **Cumplimiento de cronograma** | Entrega a tiempo                  | 100%     | Fecha de entrega final            |
| **Cobertura de requisitos**    | % de requisitos validados         | 100%     | Matriz de trazabilidad completa   |
| **Calidad de documentaci√≥n**   | Checklist de atributos completado | 100%     | Revisi√≥n contra checklist oficial |
| **Aprobaci√≥n final**           | Validaci√≥n del Product Owner      | 100%     | Confirmaci√≥n formal de aceptaci√≥n |

## KPIs Transversales del Proyecto

### Gesti√≥n y Comunicaci√≥n

| KPI                         | M√©trica                        | Objetivo | Frecuencia de Medici√≥n |
| --------------------------- | ------------------------------ | -------- | ---------------------- |
| **Comunicaci√≥n efectiva**   | Respuestas en Slack < 24h      | 90%      | Semanal                |
| **Reuniones semanales**     | Asistencia a reuniones         | 100%     | Semanal                |
| **Actualizaci√≥n de tareas** | Tareas actualizadas en ClickUp | Diario   | Diario                 |
| **Resoluci√≥n de bloqueos**  | Tiempo promedio de resoluci√≥n  | <48h     | Semanal                |

### Calidad y Riesgos

| KPI                        | M√©trica                             | Objetivo | Frecuencia de Medici√≥n |
| -------------------------- | ----------------------------------- | -------- | ---------------------- |
| **Gesti√≥n de riesgos**     | % de riesgos con plan de mitigaci√≥n | 100%     | Semanal                |
| **Incidencias cr√≠ticas**   | N√∫mero de riesgos materializados    | 0        | Semanal                |
| **Calidad de entregables** | % de entregables sin retrabajos     | 90%      | Por hito               |

## Mecanismos de Recolecci√≥n y C√°lculo

### Herramientas de Monitoreo

1. **ClickUp**: Seguimiento autom√°tico de tareas, tiempos y estados
2. **Slack**: M√©tricas de comunicaci√≥n y tiempo de respuesta
3. **GitHub**: Commits, documentaci√≥n y versiones
4. **Reuniones semanales**: Revisi√≥n manual de KPIs y ajustes

## 2. Supuestos del proyecto

### 2.1 Est√°ndares y Regulaciones

Revisi√≥n de est√°ndares y regulaciones nacionales/internacionales, incluyendo Ley 8968 (Costa Rica), GDPR, ISO/IEC 27001, OECD Data Governance y similares

### 2.2 Pr√°cticas de Manejo de C√≥digo

Definir pr√°cticas de manejo de c√≥dio (OWASp, Clean Code, Twelve-Factor App), y como las implemtaremos

### 2.3 Sistema de Versionamiento

que sistema de versionamiento se usar√° y ramas (Git Flow, GitHub Actions, Terraform,)

### 2.4 Sistemas de Teceros

Con que sistemas de terceros se interactuar√°: apis, protocolos de autenticaci√≥n (OAuth2, JWT)

### 2.5 Aspectos de Calidad/SLA

Hacer Enfasis en que ser√° Escalabilidad y Mantenibilidad, Reutilizaci√≥n y Eficiencia y Claridad y Gesti√≥n de Complejidad

## 3. Stack Tecnol√≥gico

En cada una documentar versiones de frameworks, SDKs, lenguajes y herramientas utilizadas, as√≠ como sus restricciones y licencias

- Herramientas para Frontend, Backend, Data
- Herramientas para AI
- que sistemas de Terceros, Cloud y Protocolos se usar√°n
- Herramientas para testing y DevOps

## 4. Dise√±o de los componentes

A conitnuaci√≥n cada una de estas secciones fue sacada del punto 7 de los documentos del repo del profe, hace falta aplicar cada uno de estos para todos los componentes del sistema

### An√°lisis del Componente

### Dise√±o de la Arquitectura

- Dise√±o del Frontend
- Que sistema de autenticaci√≥n se usar√°
- Como se llevar√° a cabo el KYC, y la verificaci√≥n de identidad
- Arquitectura del Client, N-Layer, Client Server, etc.
- Componentes Visuales.
- Patrones y Principios
- Toolkkits y Standards
- Estructura de carpetas del sistema
- Dise√±o del Backend
- Definir porque el sistema tiene alta disponibilidad y como
- Definir porque tiene monitoreo y como
- Definir modelo de seguridad detallado: encriptaci√≥n, auditor√≠a, logging seguro.
- REST, GraphQL, gRPC, Monolithic, or Monolithic-MVC?
- Serverless, Cloud, On-Premise, or Hybrid?
- Service vs. Microservices?
- Event-Driven, Queues, Brokers, Producer/Consumer, Pub/Sub?
- API Gateway (Security & Scalability)?
- El de arquitectura considera donde sea necesario pr√°cticas y patrones para AI. Unidad 8.
- Dise√±o de los Datos
- Como funcionar√° el proceso ETDL
- Usar como base el proyecto anterior
- El dise√±o de datos considera donde sea necesario pr√°cticas y patrones para AI. Unidad 8.

### Prototipado

No hace falta implementarlo todo, seguramente solo una prueba de concepto para algunos

### Implementaci√≥n de Componentes

No hace falta implementarlo todo, seguramente solo una prueba de concepto para algunos
solo si aplica:

- Incluir gu√≠as de integraci√≥n (how to) y ejemplos de c√≥digo funcional para los servicios principales
- Incorporar pruebas de concepto, prototipos o ejemplos que gu√≠en la futura ejecuci√≥n y validen elecciones tecnol√≥gicas

### Pruebas e Integraci√≥n

Solo explicar como se har√°

solo si aplica:

- Incluir gu√≠as de integraci√≥n (how to) y ejemplos de c√≥digo funcional para los servicios principales
- Incorporar pruebas de concepto, prototipos o ejemplos que gu√≠en la futura ejecuci√≥n y validen elecciones tecnol√≥gicas

### Despliegue y Mantenimiento

Solo explicar como se har√°, tal v√©z una prueba de concepto

### Diagrama General del Frontend

Este si es general de todos los componentes

### Diagrama General del Backend

Este si es general de todos los componentes

## 5. Validaci√≥n de los requerimientos

- Validar que el dise√±o cubre todos los requerimientos funcionales y no funcionales del sistema
- Identificar ventajas y desventajas del dise√±o, proponiendo mitigaciones a los riesgos y limitaciones
